{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kerasAssgmnt2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMVHQ4zrd5Or5UXUh7xcgLH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivanisingh28/sentimentanalysis/blob/master/kerasAssgmnt2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGMcGCICLIE2",
        "colab_type": "code",
        "outputId": "21f72e85-a05b-404e-ddd5-cfa40dae3454",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmE6iaVdT0sX",
        "colab_type": "code",
        "outputId": "445aa458-e471-44da-f316-f0dc76499b8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        }
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "# Import the pandas library to read our dataset \n",
        "import pandas as pd\n",
        "# Get the train/test split package from sklearn for preparing our dataset to # train and test the model with \n",
        "from sklearn.model_selection import train_test_split\n",
        "# Import the numpy library to work with and manipulate the data\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.set(color_codes=True)\n",
        "\n",
        "import nltk \n",
        "import random \n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt') \n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet') "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGgAttoET76s",
        "colab_type": "code",
        "outputId": "5e7c2597-222f-4191-eaa0-c8a98bef467c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "import csv\n",
        "import urllib.request as urllib2\n",
        "from nltk import FreqDist\n",
        "# Importing data using url\n",
        "url = 'https://raw.githubusercontent.com/cacoderquan/Sentiment-Analysis-on-the-Rotten-Tomatoes-movie-review-dataset/master/train.tsv'\n",
        "\n",
        "# reading data using pandas and converting into dataframe\n",
        "df = pd.read_csv(urllib2.urlopen(url),delimiter='\\t',encoding='utf-8')\n",
        "df.head()\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...  Sentiment\n",
              "0         1  ...          1\n",
              "1         2  ...          2\n",
              "2         3  ...          2\n",
              "3         4  ...          2\n",
              "4         5  ...          2\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMvLvk1BL2r5",
        "colab_type": "code",
        "outputId": "9e898524-1ef7-48fc-d580-1f38000ec4f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "df.head()\n",
        "# Check class imbalance in tokenized sentences\n",
        "df['Sentiment'].value_counts()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    79582\n",
              "3    32927\n",
              "1    27273\n",
              "4     9206\n",
              "0     7072\n",
              "Name: Sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cisMFLGmPK4K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get number of unique sentences\n",
        "numSentences = df['SentenceId'].max()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIyVbjjqPbn8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# extract full sentences only from the dataset\n",
        "fullSentences = []\n",
        "curSentence = 0\n",
        "for i in range(df.shape[0]):\n",
        "  if df['SentenceId'][i]> curSentence:\n",
        "    fullSentences.append((df['Phrase'][i], df['Sentiment'][i]))\n",
        "    curSentence = curSentence +1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AH1PicH-PiWm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# put data into a df\n",
        "fullSentDf = pd.DataFrame(fullSentences,\n",
        "                                columns=['Phrase', 'Sentiment'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wEt_MG_Pm10",
        "colab_type": "code",
        "outputId": "8148cc6b-135f-4177-a432-2b3bc540c07e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "fullSentDf['Sentiment'].value_counts()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    4232\n",
              "3    1769\n",
              "1    1591\n",
              "4     519\n",
              "0     433\n",
              "Name: Sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZfgBUOh8aR9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "documents=[]\n",
        "X_data = np.array(fullSentDf['Phrase'].values.tolist())\n",
        "Y_data = np.array(fullSentDf['Sentiment'].values.tolist())\n",
        "\n",
        "for i in range(fullSentDf.shape[0]):\n",
        "  tmpWords = word_tokenize(fullSentDf['Phrase'][i])\n",
        "  documents.append((tmpWords, fullSentDf['Sentiment'][i]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qL-78w-dUCID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords \n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer, LancasterStemmer \n",
        "porter = PorterStemmer() \n",
        "lancaster=LancasterStemmer() \n",
        "wordnet_lemmatizer = WordNetLemmatizer() \n",
        "stopwords_en = stopwords.words(\"english\") \n",
        "punctuations=\"?:!.,;'\\\"-()\"\n",
        "#parameters to adjust to see the impact on outcome \n",
        "remove_stopwords = True\n",
        "useStemming = False\n",
        "useLemma = False\n",
        "removePuncs = True\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNWEhND7UELo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for l in range(len(documents)):                   #For each review document \n",
        "  label = documents[l][1]                         #Save review label \n",
        "  tmpReview = []                                  #Placeholder list for new review \n",
        "  for w in documents[l][0]:                       #For each word this is review \n",
        "    newWord = w                                   #Set newWork to be the updated word \n",
        "    if remove_stopwords and (w in stopwords_en):  #if the word is a stopword & we want to remove stopwords \n",
        "      continue                                    #skip the word and don’t had it to the normalized review \n",
        "    if removePuncs and (w in punctuations):       #if the word is a punc. & we want to remove punctuations \n",
        "      continue                                    #skip the word and don’t had it to the normalized review \n",
        "    if useStemming:\n",
        "      #if useStemming is set to True \n",
        "      #Keep one stemmer commented out \n",
        "      #newWord = porter.stem(newWord) #User porter stemmer \n",
        "      newWord = lancaster.stem(newWord) #Use Lancaster stemmer \n",
        "    if useLemma: \n",
        "      newWord = wordnet_lemmatizer.lemmatize(newWord) \n",
        "    tmpReview.append(newWord)                     #Add normalized word to the tmp review \n",
        "  documents[l] = (tmpReview, label)             #Update the reviews list with clean review \n",
        "  documents[l] = (' '.join(tmpReview), label) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYjEsZO96hBE",
        "colab_type": "code",
        "outputId": "1f48a0af-02a5-4416-e631-ed295916eb37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "df = pd.DataFrame(documents, columns=['text', 'sentiment']) \n",
        "df.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cartoon</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>really goes downhill</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pushes</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>deeply unsettling experience</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>It 's vampires damned Queen Damned -- viewers ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  sentiment\n",
              "0                                            cartoon          2\n",
              "1                               really goes downhill          0\n",
              "2                                             pushes          2\n",
              "3                       deeply unsettling experience          1\n",
              "4  It 's vampires damned Queen Damned -- viewers ...          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7QxmVZl6yB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(df['text'],  df['sentiment'], test_size=0.3, random_state=2003)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daoUPAFVUMPK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b1a21672-f8de-44ac-e478-561df0ba7672"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer , TfidfVectorizer\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features = 2000,ngram_range=(2, 2)) \n",
        "X = vectorizer.fit_transform(df[\"text\"]) \n",
        "Y = df['sentiment'] \n",
        " \n",
        "X_train = vectorizer.transform(X_train).toarray()\n",
        "Y_train = Y_train \n",
        "X_test = vectorizer.transform(X_test).toarray()\n",
        "Y_test = Y_test"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qclubi30UPRD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dujbykr67GjH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def recallfunction(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shFWIZWH7I-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def precisionfunction(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqdL15Sl7Unx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f1function(y_true, y_pred):\n",
        "    precision = precisionfunction(y_true, y_pred)\n",
        "    recall = recallfunction(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmPiQ190UTtw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "num_classes = 5\n",
        "epochs = 12"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FI_tkwheUUk9",
        "colab_type": "code",
        "outputId": "29c6ff45-bd76-4d45-ff73-0a02cdb178e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_train.shape\n",
        "# Y_train = to_categorical(Y_train,5)\n",
        "# y_test = to_categorical(y_test,5)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5980, 2000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ua_crvw-UWp7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
        "Y_test = keras.utils.to_categorical(Y_test, num_classes)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiXbfjUCUaqh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "908bf175-43ca-4126-fd18-f843defe4fbf"
      },
      "source": [
        "\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=3,\n",
        "                 activation='relu',\n",
        "                 input_shape=(2000,1)))\n",
        "model.add(Conv1D(128, kernel_size=5, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=1))\n",
        "model.add(Dropout(rate = 0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes, activation='softmax'))\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uH9NkDeOUdfa",
        "colab_type": "code",
        "outputId": "ce64a549-e726-4e59-cd57-4e3805d75ffd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adam(),\n",
        "              metrics=['accuracy',f1function,precisionfunction, recallfunction])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_1 (Conv1D)            (None, 1998, 64)          256       \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1994, 128)         41088     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 1994, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1994, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 255232)            0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 1276165   \n",
            "=================================================================\n",
            "Total params: 1,317,509\n",
            "Trainable params: 1,317,509\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwZpXGqZUgCu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZYUBUFCUhtA",
        "colab_type": "code",
        "outputId": "b1b0e4c0-a13f-486e-fa4a-5c4879231acc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        }
      },
      "source": [
        "model.fit(X_train, Y_train,\n",
        "          batch_size=64,\n",
        "          epochs=8)\n",
        "model.save('/content/drive/My Drive/my_model.h5')\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "print('Test F1 score:', score[2])\n",
        "print('Test precision:', score[3])\n",
        "print('Test recall:', score[4])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "5980/5980 [==============================] - 2s 294us/step - loss: 0.9735 - acc: 0.6005 - f1function: 0.5923 - precisionfunction: 0.6170 - recallfunction: 0.5749\n",
            "Epoch 2/8\n",
            "5980/5980 [==============================] - 2s 291us/step - loss: 0.9736 - acc: 0.6025 - f1function: 0.5742 - precisionfunction: 0.6280 - recallfunction: 0.5505\n",
            "Epoch 3/8\n",
            "5980/5980 [==============================] - 2s 292us/step - loss: 0.9730 - acc: 0.6007 - f1function: 0.5986 - precisionfunction: 0.6121 - recallfunction: 0.5870\n",
            "Epoch 4/8\n",
            "5980/5980 [==============================] - 2s 292us/step - loss: 0.9707 - acc: 0.6065 - f1function: 0.5877 - precisionfunction: 0.6272 - recallfunction: 0.5669\n",
            "Epoch 5/8\n",
            "5980/5980 [==============================] - 2s 290us/step - loss: 0.9751 - acc: 0.6050 - f1function: 0.5578 - precisionfunction: 0.6505 - recallfunction: 0.5227\n",
            "Epoch 6/8\n",
            "5980/5980 [==============================] - 2s 286us/step - loss: 0.9721 - acc: 0.6047 - f1function: 0.5436 - precisionfunction: 0.6590 - recallfunction: 0.5002\n",
            "Epoch 7/8\n",
            "5980/5980 [==============================] - 2s 287us/step - loss: 0.9712 - acc: 0.6027 - f1function: 0.5801 - precisionfunction: 0.6227 - recallfunction: 0.5570\n",
            "Epoch 8/8\n",
            "5980/5980 [==============================] - 2s 286us/step - loss: 0.9714 - acc: 0.6040 - f1function: 0.5941 - precisionfunction: 0.6148 - recallfunction: 0.5776\n",
            "Test loss: 1.7501658072895638\n",
            "Test accuracy: 0.5015600624024961\n",
            "Test F1 score: 0.4986839873742388\n",
            "Test precision: 0.5043416778308553\n",
            "Test recall: 0.49336973478939156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wHd6gBtUjeQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('/content/drive/My Drive/my_model.h5',custom_objects={'f1function':f1function,'precisionfunction':precisionfunction,'recallfunction':recallfunction})\n",
        "model.save('my_model.h5')  # creates a HDF5 file\n",
        "#del model  # deletes the existing model"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}